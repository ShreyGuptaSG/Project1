{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUSA8001 Applied Predictive Analytics - Programming Task 2\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment Points**: 100  \n",
    "**Assignment Weight**: 10%  \n",
    "**Due Date**: Fri, 27 August 2021 @ 11.59pm  \n",
    "**Submission**: Submit your file using the submission link on iLearn\n",
    "\n",
    "\n",
    "Put **all your work** into a file titled `BUSA8001_programming_task2_MQ_ID.ipynb` where MQ_ID is your Macquarie University student ID number (e.g. if MQ_ID == 12345678 then you need to submit BUSA8001_programming_task2_12345678.ipynb). \n",
    "\n",
    "- Failure to submit a correctly named file will result in a loss of 30 points.\n",
    "- Failure to supply solutions in the cells provided below each question will result in a loss of 30 points.\n",
    "- Follow all instructions closely and not print your variables to screen unless explicitly asked to do so. Failure to do so will result in additional point deductions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1 - (30 points)\n",
    "\n",
    "**Perform the following tasks in python, writing your code in the cells provided underneath each question.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Import the credit card data from https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls directly into a pandas DataFrame named `df` making sure you skip the top row when reading the dataset. Delete the 'ID\" column after importing the data. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls', skiprows=[0])\n",
    "del df['ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Q2. Rename the column 'PAY_0' to 'PAY_1' and the column 'default payment next month' to 'payment_default' (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'PAY_0': 'PAY_1', 'default payment next month': 'payment_default'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Q3. Create a one-dimensional NumPy array named `y` by exporting the first 12,500 observations of 'payment_default' column from df (hint: see `ravel` NumPy method). Similarly, create a two-dimensional NumPy array named `X` by exporting the first 12,500 observatations of 'PAY_1', 'PAY_2', 'AGE', 'SEX', 'MARRIAGE', 'EDUCATION' and 'BILL_AMT1' columns. (10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['payment_default'].loc[:12499].values\n",
    "X = df[['PAY_1', 'AGE', 'SEX', 'MARRIAGE', 'EDUCATION', 'BILL_AMT1']].loc[:12499].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Q4. Use an appropriate `scikit-learn` library we learned in class to create the following NumPy arrays: `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 68% train and 32% test datasets. Set `random_state` to 3 and stratify subsamples so that train and test datasets have roughly equal proportions of the target's class labels. (5 points) \n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.32, random_state = 3, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Q5. Use an appropriate `scikit-learn` library we learned in class to standardize features from train and test datasets to mean zero and variance one, as discussed in class. (5 points)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "# print(X_train_scaled)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "## Problem 2 - (30 Points)\n",
    "\n",
    "Q6. Using approapriate `scikit-learn` libararies we learned in class to fit the following classifiers to the training dataset constructed in Problem 1. \n",
    "\n",
    "- Logistic Regression - name your instance `lr` set `random_state=5`\n",
    "- Support Vector Machine with Linear Kernel - name your instance `svm_linear` set `C=5.0` and `random_state=5`\n",
    "- Support Vector Machine with RBF Kernel - name your instance `svm_rbf` set `gamma = 20`, `C=5.0`, `random_state=5`\n",
    "- Decision Tree - name your instance `tree` set `criterion='entropy'`, `max_depth = 5`, `random_state=5`\n",
    "- Random Forest - name your instance  `forest` set `criterion='entropy'`, `n_estimators=20`, `random_state=5`\n",
    "- KNN - name your instance `knn` set `n_neighbors=7`, `p=2`, `metric='minkowski'`\n",
    "    \n",
    "When initializing instances of the above classifiers only set parameters provided above and leave all other parameters equal to their `scikit-learn` default values.  (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "lr = LogisticRegression(random_state=5)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_linear = SVC(kernel='linear', C=5.0, random_state=5)\n",
    "svm_linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', gamma = 20, C=5.0, random_state=5)\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth = 5, random_state=5)\n",
    "tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=20, random_state=5)\n",
    "forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7, p=2, metric='minkowski')\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3 - (40 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Using a method built into each of the above classifiers, compute prediction accuracy on training data for each classifier and store it into variables named according to the following pattern: `classifier_name_accuracy_train`, for instance you should have `lr_accuracy_train`. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracy_train=f'lr_accuracy_train = {lr.score(X_train_scaled, y_train):5f}'\n",
    "# print(lr_accuracy_train)\n",
    "svm_linear_accuracy_train = f'svm_linear_accuracy_train = {svm_linear.score(X_train_scaled, y_train):5f}'\n",
    "# print(svm_linear_accuracy_train)\n",
    "svm_rbf_accuracy_train = f'svm_rbf_accuracy_train = {svm_rbf.score(X_train_scaled, y_train):5f}'\n",
    "# print(svm_rbf_accuracy_train)\n",
    "tree_accuracy_train = f'tree_accuracy_train = {tree.score(X_train_scaled, y_train):5f}'\n",
    "# print(tree_accuracy_train)\n",
    "forest_accuracy_train=f'forest_accuracy_train = {forest.score(X_train_scaled, y_train):5f}'\n",
    "# print(forest_accuracy_train)\n",
    "knn_accuracy_train=f'knn_accuracy_train = {knn.score(X_train_scaled, y_train):5f}'\n",
    "# print(knn_accuracy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Q8. Using a method built into each of the above classifiers, compute prediction accuracy on test data for each classifier and store it into variables named according to the following pattern: `classifier_name_accuracy_test`, for instance you should have `lr_accuracy_test`. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_accuracy_train = 0.788588\n",
      "svm_linear_accuracy_train = 0.775647\n",
      "svm_rbf_accuracy_train = 0.889882\n",
      "tree_accuracy_train = 0.809294\n",
      "forest_accuracy_train = 0.974706\n",
      "knn_accuracy_train = 0.817176\n"
     ]
    }
   ],
   "source": [
    "print(lr_accuracy_train)\n",
    "print(svm_linear_accuracy_train)\n",
    "print(svm_rbf_accuracy_train)\n",
    "print(tree_accuracy_train)\n",
    "print(forest_accuracy_train)\n",
    "print(knn_accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracy_test=f'lr_accuracy_test = {lr.score(X_test_scaled, y_test):5f}'\n",
    "svm_linear_accuracy_test=f'svm_linear_accuracy_test = {svm_linear.score(X_test_scaled, y_test):5f}'\n",
    "svm_rbf_accuracy_test=f'svm_rbf_accuracy_test = {svm_rbf.score(X_test_scaled, y_test):5f}'\n",
    "tree_accuracy_test=f'tree_accuracy_test = {tree.score(X_test_scaled, y_test):5f}'\n",
    "forest_accuracy_test=f'forest_accuracy_test = {forest.score(X_test_scaled, y_test):5f}'\n",
    "knn_accuracy_test=f'knn_accuracy_test = {knn.score(X_test_scaled, y_test):5f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Q9. Explain which methods rank in the first two places according to their ability to accurately classify train data, and which two methods perform worst on train dataset? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The two best models on training dataset are Random Forest and KNN. And, worst performed on dataset are these two methods- Support Vector Machine with Linear Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Q10. \n",
    "- Exaplain which methods rank in the first two places according to their ability to accurately classify test data, and which two methods perform worst on test dataset? (3 marks)\n",
    "- How do these accuracies compare with the ones reported in Q9? Is this expected, and why (or why not)? (7 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Support Vector Machine with RBF Kernel and Decision Tree are top 2 classifiers according to accuretly classifying train data. Whereas, Support Vector Machine with Linear Kernel and Random Forest performed perform worst on test dataset.\n",
    "It was not expected, as the best models differs in training and testing data. Also, Support Vector Machine with RBF Kernel and Support Vector Machine with Linear Kernel had closely similar accuracy in both training and test data. Whereas, all the other methods performed differently on test data set. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
